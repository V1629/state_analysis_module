```mermaid
graph TD
    A[User Message] --> B{Signal Extractor}
    
    B --> C[Lexical Analyzer]
    B --> D[Temporal Parser]
    B --> E[Functional Detector]
    B --> F[Emotional Calibrator]
    
    C --> G{Confidence Scorer}
    D --> G
    E --> G
    F --> G
    
    G -->|Confidence < 0.65| H[Generate Probe Question]
    H --> A
    
    G -->|Confidence â‰¥ 0.65| I[PRISM Calculator]
    
    I --> J{Classification Engine}
    
    J -->|SS < 15| K[ST State]
    J -->|15 â‰¤ SS < 75| L[MT State]
    J -->|SS â‰¥ 75| M[LT State]
    
    K --> N[State Machine]
    L --> N
    M --> N
    
    N --> O{Transition Validator}
    
    O -->|Check Compounding| P[Compounding Analyzer]
    P -->|3 ST in 7d| Q[Escalate to MT]
    
    O -->|Check Resurgence| R[Resurgence Handler]
    R -->|Anniversary/Trigger| S[Reactivate LT]
    
    Q --> T[Storage Layer]
    S --> T
    N --> T
    
    T --> U[(Redis - ST Cache)]
    T --> V[(MongoDB - MT/LT)]
    T --> W[(MongoDB - Event Relationships)]
    T --> X[(MongoDB - Vector Embeddings)]
    
    U -.->|Auto-Expire 14d| Y[Decay Engine]
    V -.->|Daily Recalc| Y
    
    Y --> Z[Query Optimizer]
    W --> Z
    X --> Z
    
    Z --> AA[Context Builder]
    AA --> AB{State Context Output}
    
    AB -->|ST Dominant| AC[Casual Context Flags]
    AB -->|MT Dominant| AD[Attentive Context Flags]
    AB -->|LT Dominant| AE[Deep Empathy Context Flags]
    
    AC --> AF[Export to Main Response Pipeline]
    AD --> AF
    AE --> AF
    
    AF --> AG[Combined with Other Modules]
    
    style A fill:#e1f5ff
    style AG fill:#e1f5ff
    style T fill:#fff4e1
    style Y fill:#ffe1e1
    style AB fill:#e1ffe1
    
    classDef storage fill:#f9f9f9,stroke:#333,stroke-width:2px
    class U,V,W,X storage
```

# Temporal State Engine

A sophisticated AI module for tracking and adapting to users' emotional states across three temporal dimensions: Short-Term (ST), Mid-Term (MT), and Long-Term (LT).

## ğŸ“ Module Structure
```
temporal_state_engine/
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                    # Pydantic models for Incident, StateTransition
â”‚   â”œâ”€â”€ enums.py                     # StateLayer, LifeDomain, ImpairmentLevel
â”‚   â””â”€â”€ config.py                    # Decay constants, thresholds, domain weights
â”‚
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ signal_extractor.py          # Main extraction orchestrator
â”‚   â”œâ”€â”€ lexical_analyzer.py          # Keyword/phrase pattern matching
â”‚   â”œâ”€â”€ temporal_parser.py           # Date/duration extraction (using dateparser)
â”‚   â”œâ”€â”€ functional_detector.py       # Life domain impairment detection
â”‚   â”œâ”€â”€ emotional_calibrator.py      # User baseline normalization
â”‚   â””â”€â”€ confidence_scorer.py         # Multi-signal agreement calculation
â”‚
â”œâ”€â”€ scoring/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prism_calculator.py          # PRISM score computation
â”‚   â”œâ”€â”€ classification_engine.py     # ST/MT/LT threshold assignment
â”‚   â”œâ”€â”€ compounding_analyzer.py      # Cluster detection (3 ST â†’ MT)
â”‚   â””â”€â”€ similarity_matcher.py        # Vector-based incident comparison
â”‚
â”œâ”€â”€ state_management/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ state_machine.py             # Core FSM for state transitions
â”‚   â”œâ”€â”€ decay_engine.py              # Time-based relevance recalculation
â”‚   â”œâ”€â”€ resurgence_handler.py        # Trauma trigger detection & reactivation
â”‚   â”œâ”€â”€ transition_validator.py      # Rule-based escalation/demotion checks
â”‚   â””â”€â”€ snapshot_manager.py          # Historical state capture for audit
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ redis_client.py              # ST layer (volatile cache with TTL)
â”‚   â”œâ”€â”€ mongodb_client.py            # Main MongoDB connection manager
â”‚   â”œâ”€â”€ collections/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ incidents.py             # MT/LT incidents collection handler
â”‚   â”‚   â”œâ”€â”€ event_graph.py           # Event relationships collection
â”‚   â”‚   â”œâ”€â”€ embeddings.py            # Vector embeddings collection
â”‚   â”‚   â””â”€â”€ user_baselines.py       # User emotional calibration data
â”‚   â””â”€â”€ indexes/
â”‚       â”œâ”€â”€ incident_indexes.py      # user_id, state_layer, created_at indexes
â”‚       â””â”€â”€ vector_indexes.py        # MongoDB vector search indexes
â”‚
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py                  # End-to-end processing pipeline
â”‚   â”œâ”€â”€ background_jobs.py           # Scheduled decay recalculations
â”‚   â”œâ”€â”€ event_bus.py                 # Pub/sub for state change notifications
â”‚   â””â”€â”€ query_optimizer.py           # Cross-layer retrieval strategies
â”‚
â”œâ”€â”€ context_export/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_builder.py           # Assembles relevant incidents for export
â”‚   â”œâ”€â”€ state_summarizer.py          # Creates state distribution summary
â”‚   â””â”€â”€ empathy_flags.py             # Generates context flags for main pipeline
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                    # Structured logging with PII scrubbing
â”‚   â”œâ”€â”€ metrics.py                   # Classification accuracy tracking
â”‚   â””â”€â”€ validators.py                # Input sanitization & schema validation
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_prism_calculator.py
â”‚   â”‚   â”œâ”€â”€ test_decay_engine.py
â”‚   â”‚   â”œâ”€â”€ test_state_machine.py
â”‚   â”‚   â””â”€â”€ test_mongodb_collections.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_end_to_end_pipeline.py
â”‚   â”‚   â””â”€â”€ test_storage_layer.py
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ sample_conversations.json
â”‚       â””â”€â”€ mock_user_histories.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ module_overview.md           # High-level module purpose
â”‚   â”œâ”€â”€ integration_guide.md         # How to integrate with main project
â”‚   â”œâ”€â”€ api_reference.md             # Function signatures & examples
â”‚   â””â”€â”€ clinical_safety.md           # Suicide risk protocols
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_database.py             # Load test data
â”‚   â”œâ”€â”€ recalculate_all_states.py   # Batch reprocessing script
â”‚   â””â”€â”€ export_user_timeline.py     # Debugging/audit tool
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ docker-compose.yml               # Redis + MongoDB services
â””â”€â”€ README.md
```

## ğŸ¯ Overview

The Temporal State Engine analyzes user conversations to detect and track life incidents across three temporal states:

- **Short-Term (ST):** Transient moods and minor daily incidents (0-14 days)
- **Mid-Term (MT):** Ongoing situations from recent significant events (2 weeks - 4 months)
- **Long-Term (LT):** Deep shifts from life-altering events (permanent baseline)

## ğŸ§  Core Features

### PRISM Scoring Framework
```
Significance Score = (P Ã— R Ã— I Ã— S) / M

Where:
- P (Persistence): Expected duration [0.1-10.0]
- R (Resonance): Emotional intensity [1-10]
- I (Impact): Life domain breadth [1-5]
- S (Severity): Functional impairment [0.1-3.0]
- M (Malleability): Perceived control [0.5-2.0]
```

### State Classification
- **ST**: Score < 15
- **MT**: Score 15-75
- **LT**: Score â‰¥ 75

### Multi-Signal Extraction
1. **Lexical Analysis**: Emotion word detection and sentiment scoring
2. **Temporal Parsing**: Time reference extraction and duration calculation
3. **Functional Detection**: Life domain impact assessment
4. **Emotional Calibration**: User baseline normalization



```

### Basic Usage
```python
from temporal_state_engine.orchestration.pipeline import process_user_message

# Process a user message
result = await process_user_message(
    message="I've been really stressed about my job for the last month",
    user_id="user_123"
)

# Access temporal context
print(result['dominant_state'])  # 'MT'
print(result['empathy_level'])   # 'moderate'
```

## ğŸ—„ï¸ Storage Architecture

### Redis (Short-Term)
- Auto-expiring cache (14-day TTL)
- Fast incident retrieval
- Sorted sets for chronological ordering

### MongoDB (Mid/Long-Term)
- **Collections:**
  - `incidents`: MT/LT incident storage
  - `event_graph`: Incident relationships
  - `embeddings`: Vector search for similarity
  - `user_baselines`: Calibration data

## State Transition & Decay

### Short-Term Decay
```python
Relevance(t) = Initial_SS Ã— e^(-0.3t)
# 70% reduction every 2 days
```

### Mid-Term Decay
```python
Relevance(t) = Initial_SS / (1 + e^(k(t - t_half)))
# S-curve decay over 60-120 days
```

### Long-Term Decay
```python
Relevance(t) = Baseline_SS + (Initial_SS - Baseline_SS) Ã— e^(-Î¼t) + Î¾(t)
# Asymptotic with trauma resurgence
```

## ğŸ”— Integration

This module exports context data to the main application pipeline:
```python
temporal_context = {
    "dominant_state": "MT",
    "state_distribution": {"ST": 0.15, "MT": 0.60, "LT": 0.25},
    "empathy_level": "moderate",
    "tone_recommendation": "attentive_validating",
    "active_incidents": [...]
}
```





## ğŸ› ï¸ Configuration

Key configuration in `core/config.py`:
```python
# State thresholds
ST_THRESHOLD = 15
MT_THRESHOLD = 75

# Decay constants
ST_DECAY_LAMBDA = 0.3
MT_HALF_LIFE_DAYS = 60

# Life domains
LIFE_DOMAINS = ['work', 'relationships', 'health', 'identity', 'safety']
```